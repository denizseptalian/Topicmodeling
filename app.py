# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1n30H6z9syQvFxL0nAIDnOusemL2tA9di
"""

import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.decomposition import LatentDirichletAllocation

# Define the function to perform the crawling and LDA
def crawl_and_analyze(keyword):
    # Replace this with actual crawling code
    # Here, we're using a dummy dataframe for illustration
    documents = [
        "This is a sample document related to " + keyword,
        "Another document about " + keyword,
        "More text data with " + keyword,
    ]
    df = pd.DataFrame(documents, columns=['document'])

    # Perform text processing and LDA
    vectorizer = CountVectorizer(stop_words='english')
    X = vectorizer.fit_transform(df['document'])

    lda = LatentDirichletAllocation(n_components=3, random_state=42)
    lda.fit(X)

    # Extract topics and word cloud data
    topics = lda.components_
    feature_names = vectorizer.get_feature_names_out()

    # Create a dataframe for dominant topic
    df_dominant_topic = pd.DataFrame({
        "Document": df['document'],
        "Dominant Topic": np.argmax(lda.transform(X), axis=1)
    })

    return df_dominant_topic, topics, feature_names

# Streamlit UI
st.title("Keyword Crawling and LDA Analysis")

# Input keyword
keyword = st.text_input("Enter a keyword for crawling:")

if keyword:
    # Perform crawling and analysis
    df_dominant_topic, topics, feature_names = crawl_and_analyze(keyword)

    # Display the dataframe
    st.subheader("Dominant Topic DataFrame")
    st.dataframe(df_dominant_topic)

    # Wordcloud visualization
    st.subheader("Word Cloud")
    wordcloud = WordCloud(width=800, height=400).generate(' '.join(df_dominant_topic['Document']))
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis('off')
    st.pyplot(plt)

    # LDA visualization
    st.subheader("LDA Topics")
    for idx, topic in enumerate(topics):
        st.write(f"Topic {idx + 1}")
        topic_words = [feature_names[i] for i in topic.argsort()[:-11:-1]]
        st.write(' '.join(topic_words))

# Run the app with streamlit run script_name.py
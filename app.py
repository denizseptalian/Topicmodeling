import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from GoogleNews import GoogleNews
import streamlit as st
from wordcloud import WordCloud
import logging
from collections import Counter
from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory
import re

logging.basicConfig(level=logging.INFO)

# Function to preprocess the text
def preprocess_text(text):
    if pd.isna(text):
        return ""
    # Remove irrelevant characters
    text = re.sub(r'[^a-zA-Z0-9\s]', '', text)
    # Remove stopwords
    factory = StopWordRemoverFactory()
    stopword = factory.create_stop_word_remover()
    text = stopword.remove(text)
    return text

# Function to crawl and analyze data
def crawl_and_analyze(keyword):
    googlenews = GoogleNews(lang='id', region='ID')
    googlenews.search(keyword)
    
    # Collect data from multiple pages
    data_to_append = []
    for i in range(1, 11):
        googlenews.getpage(i)
        news = googlenews.results()
        df_temp = pd.DataFrame(news)
        data_to_append.append(df_temp)
    
    # Concatenate all the data into one DataFrame
    df = pd.concat(data_to_append, ignore_index=True) if data_to_append else pd.DataFrame()
    
    if df.empty or 'title' not in df.columns:
        return None, None, None, None
    
    # Preprocess the text data
    df['title'] = df['title'].fillna('')
    df['desc'] = df['desc'].fillna('')
    documents = df['title'] + ' ' + df['desc']  # Combine title and description
    df_texts = df.copy()
    df_texts['document'] = documents.apply(preprocess_text)
    
    # Generate word cloud
    long_string = ', '.join(df_texts['document'].values)
    wordcloud = WordCloud(background_color="white", max_words=5000, contour_width=3, contour_color='steelblue').generate(long_string)
    
    # Count most common words
    words = long_string.split()
    word_counts = Counter(words)
    most_common_words = word_counts.most_common(10)
    
    # Analyze top 10 media sources
    top_media = df['media'].value_counts().head(10) if 'media' in df.columns else pd.Series()
    
    return df_texts, wordcloud, most_common_words, top_media

# Streamlit UI Styling
st.set_page_config(page_title="Keyword Crawling Analysis", layout="wide")
st.markdown("""
    <style>
    .main {
        background-color: #f0f2f6;
    }
    h1, h2, h3 {
        color: #2E3B55;
    }
    .stDataFrame {
        background-color: white;
        border-radius: 10px;
        padding: 10px;
    }
    </style>
    """, unsafe_allow_html=True)

st.title("üîç Keyword Crawling & Analysis")
st.write("Crawl berita dari Google News berdasarkan kata kunci dan analisis hasilnya dengan visualisasi yang menarik.")

# Input keyword
keyword = st.text_input("üìù Masukkan Kata Kunci untuk Crawling:", placeholder="Contoh: Teknologi, Politik, Ekonomi")

if keyword:
    try:
        # Perform crawling and analysis
        df_texts, wordcloud, most_common_words, top_media = crawl_and_analyze(keyword)
        
        if df_texts is None:
            st.error("‚ùå Tidak ada berita yang ditemukan untuk kata kunci ini.")
        else:
            # Display the dataframe
            st.subheader("üìä Data Berita yang Dikumpulkan")
            st.dataframe(df_texts.drop(columns=['date'], errors='ignore'), height=400)
            
            # Word cloud visualization
            st.subheader("‚òÅÔ∏è Word Cloud")
            fig, ax = plt.subplots(figsize=(10, 5))
            ax.imshow(wordcloud, interpolation='bilinear')
            ax.axis('off')
            st.pyplot(fig)
            
            # Display most common words
            st.subheader("üìå 10 Kata Paling Sering Muncul")
            st.table(pd.DataFrame(most_common_words, columns=["Kata", "Jumlah"], index=range(1, 11)))
            
            # Display top 10 media sources
            if not top_media.empty:
                st.subheader("üèÜ 10 Media Paling Aktif")
                st.table(pd.DataFrame(top_media).reset_index().rename(columns={'index': 'Media', 'media': 'Jumlah Berita'}))
            else:
                st.warning("‚ö†Ô∏è Tidak ada data media yang ditemukan.")
    
    except Exception as e:
        logging.exception("An error occurred during processing.")
        st.error(f"‚ùå Terjadi kesalahan: {e}")
